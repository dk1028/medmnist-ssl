{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Basics with MedMNIST (Binary 2D) — Colab\n",
        "Use **breastmnist** or **pneumoniamnist**. Set runtime to **GPU**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install"
      },
      "source": [
        "!pip -q install torch torchvision medmnist scikit-learn matplotlib tqdm\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, random, json, numpy as np\nimport torch, torch.nn as nn\nfrom torch.utils.data import DataLoader, Subset\nimport torchvision.transforms as T\nimport torchvision.models as tvm\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nimport medmnist\nfrom medmnist import INFO\n\ndef set_seed(seed: int = 42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nclass AverageMeter:\n    def __init__(self): self.reset()\n    def reset(self): self.sum = 0.0; self.cnt = 0\n    def update(self, val, n=1): self.sum += float(val) * n; self.cnt += n\n    @property\n    def avg(self): return self.sum / max(1, self.cnt)\n\ndef compute_metrics(y_true, y_prob, n_classes):\n    y_pred = np.argmax(y_prob, axis=1)\n    acc = accuracy_score(y_true, y_pred)\n    if n_classes == 2:\n        auroc = roc_auc_score(y_true, y_prob[:,1])\n    else:\n        y_true_1hot = np.eye(n_classes)[y_true]\n        try:\n            auroc = roc_auc_score(y_true_1hot, y_prob, average=\"macro\", multi_class=\"ovr\")\n        except Exception:\n            auroc = np.nan\n    return {\"acc\": acc, \"auroc\": auroc}\n\ndef reliability_diagram(y_true, y_prob, n_bins=10):\n    confidences = np.max(y_prob, axis=1)\n    preds = np.argmax(y_prob, axis=1)\n    correct = (preds == y_true).astype(np.float32)\n    bins = np.linspace(0, 1, n_bins+1)\n    ece = 0.0\n    bin_accs, bin_confs = [], []\n    xs = np.linspace(0.5/n_bins, 1-0.5/n_bins, n_bins)\n    for i in range(n_bins):\n        lo, hi = bins[i], bins[i+1]\n        mask = (confidences > lo) & (confidences <= hi) if i>0 else (confidences >= lo) & (confidences <= hi)\n        if mask.sum() == 0:\n            bin_accs.append(0.0); bin_confs.append((lo+hi)/2); continue\n        acc_i = correct[mask].mean()\n        conf_i = confidences[mask].mean()\n        frac_i = mask.mean()\n        ece += abs(acc_i - conf_i) * frac_i\n        bin_accs.append(acc_i); bin_confs.append(conf_i)\n    plt.figure(); plt.plot([0,1],[0,1], linestyle='--')\n    plt.bar(xs, bin_accs, width=1.0/n_bins, alpha=0.6, edgecolor='k')\n    plt.plot(xs, bin_confs, marker='o')\n    plt.xlabel(\"Confidence\"); plt.ylabel(\"Accuracy\")\n    plt.title(f\"Reliability Diagram (ECE={ece:.3f})\")\n    plt.tight_layout(); plt.show()\n    return float(ece)\n\ndef get_medmnist_dataset(key: str, split: str, as_rgb=True, size=64, download=True):\n    info = INFO[key]\n    DataClass = getattr(medmnist, info['python_class'])\n    tf = [T.Resize((size,size)), T.ToTensor()]\n    if as_rgb: tf.append(T.Lambda(lambda x: x.repeat(3,1,1) if x.shape[0]==1 else x))\n    transform = T.Compose(tf)\n    return DataClass(split=split, transform=transform, download=download)\n\ndef get_loaders(key, batch_size=128, num_workers=2, label_frac=1.0, seed=42):\n    set_seed(seed)\n    ds_train = get_medmnist_dataset(key, 'train')\n    ds_val   = get_medmnist_dataset(key, 'val')\n    ds_test  = get_medmnist_dataset(key, 'test')\n    n_classes = len(INFO[key]['label'])\n    if 0 < label_frac < 1.0:\n        y = np.array([int(t[1]) for t in ds_train])\n        idxs = []\n        for c in np.unique(y):\n            cls_idx = np.where(y==c)[0]\n            k = max(1, int(len(cls_idx)*label_frac))\n            idxs.extend(np.random.choice(cls_idx, size=k, replace=False))\n        ds_train = Subset(ds_train, sorted(idxs))\n    train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n    val_loader   = DataLoader(ds_val, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n    test_loader  = DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n    return train_loader, val_loader, test_loader, n_classes\n\nclass SmallCNN(nn.Module):\n    def __init__(self, in_ch=3, n_classes=2):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(in_ch, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d(1),\n        )\n        self.fc = nn.Linear(128, n_classes)\n    def forward(self, x):\n        feat = self.net(x).flatten(1)\n        return self.fc(feat)\n\ndef make_resnet18(n_classes=2, in_ch=3, pretrained=True):\n    m = tvm.resnet18(weights=tvm.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)\n    if in_ch != 3:\n        w = m.conv1.weight\n        m.conv1 = torch.nn.Conv2d(in_ch, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        if in_ch == 1:\n            with torch.no_grad():\n                m.conv1.weight.copy_(w.sum(dim=1, keepdim=True))\n    in_dim = m.fc.in_features\n    m.fc = torch.nn.Linear(in_dim, n_classes)\n    return m\n\nprint('✅ Setup ready')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---- Config (choose ONE binary dataset) ----\nset_seed(42)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint('Device:', device)\n\nDATASET_KEY = 'pneumoniamnist'  # or 'breastmnist'\nMODEL_NAME  = 'resnet18'        # 'smallcnn' if slow\nEPOCHS      = 5\nBATCH_SIZE  = 128\nLR          = 3e-4\nWEIGHT_DECAY= 1e-4\nFINETUNE    = 'head'            # 'head' or 'all' (for resnet18)\nECE_BINS    = 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---- Train & evaluate once ----\ntrain_loader, val_loader, test_loader, n_classes = get_loaders(DATASET_KEY, batch_size=BATCH_SIZE, label_frac=1.0, seed=42)\n\nif MODEL_NAME == 'smallcnn':\n    model = SmallCNN(in_ch=3, n_classes=n_classes)\n    params = model.parameters()\nelse:\n    model = make_resnet18(n_classes=n_classes, in_ch=3, pretrained=True)\n    if FINETUNE == 'head':\n        for p in model.parameters(): p.requires_grad = False\n        for p in model.fc.parameters(): p.requires_grad = True\n        params = model.fc.parameters()\n    else:\n        params = model.parameters()\n\nmodel.to(device)\nopt = torch.optim.AdamW(params, lr=LR, weight_decay=WEIGHT_DECAY)\nsch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\ncriterion = torch.nn.CrossEntropyLoss()\n\nbest_score = -1.0; best_state = None\nfor epoch in range(1, EPOCHS+1):\n    # train\n    model.train()\n    loss_sum = 0.0; n_sum = 0\n    for x,y in train_loader:\n        x = x.to(device); y = y.long().to(device)\n        logits = model(x)\n        loss = criterion(logits, y)\n        opt.zero_grad(); loss.backward(); opt.step()\n        loss_sum += float(loss.item()) * x.size(0); n_sum += x.size(0)\n    # val\n    model.eval()\n    with torch.no_grad():\n        from numpy import argmax\n        import numpy as np\n        yv, pv = [], []\n        for x,y in val_loader:\n            x=x.to(device)\n            p = torch.softmax(model(x), dim=1).cpu().numpy()\n            pv.append(p); yv.append(y.numpy())\n        pv = np.concatenate(pv, 0); yv = np.concatenate(yv, 0)\n    from sklearn.metrics import roc_auc_score, accuracy_score\n    acc = accuracy_score(yv, np.argmax(pv, axis=1))\n    try:\n        auroc = roc_auc_score(yv, pv[:,1])\n    except Exception:\n        auroc = float('nan')\n    score = auroc if auroc==auroc else acc\n    print(f\"[{epoch:02d}] loss={loss_sum/max(1,n_sum):.4f} | val acc={acc:.4f} auroc={auroc:.4f}\")\n    sch.step()\n\n# test\nif best_state is not None:\n    model.load_state_dict(best_state, strict=True)\nyt, pt = [], []\nwith torch.no_grad():\n    for x,y in test_loader:\n        x=x.to(device)\n        p = torch.softmax(model(x), dim=1).cpu().numpy()\n        pt.append(p); yt.append(y.numpy())\nimport numpy as np\npt = np.concatenate(pt, 0); yt = np.concatenate(yt, 0)\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nacc = accuracy_score(yt, np.argmax(pt, axis=1))\ntry:\n    auroc = roc_auc_score(yt, pt[:,1])\nexcept Exception:\n    auroc = float('nan')\nprint(f\"TEST | acc={acc:.4f} auroc={auroc:.4f}\")\n\nfrom math import isnan\ndef reliability_diagram_inline(y_true, y_prob, n_bins=10):\n    confidences = np.max(y_prob, axis=1)\n    preds = np.argmax(y_prob, axis=1)\n    correct = (preds == y_true).astype(np.float32)\n    bins = np.linspace(0, 1, n_bins+1)\n    ece = 0.0\n    xs = np.linspace(0.5/n_bins, 1-0.5/n_bins, n_bins)\n    bin_accs, bin_confs = [], []\n    for i in range(n_bins):\n        lo, hi = bins[i], bins[i+1]\n        mask = (confidences > lo) & (confidences <= hi) if i>0 else (confidences >= lo) & (confidences <= hi)\n        if mask.sum() == 0:\n            bin_accs.append(0.0); bin_confs.append((lo+hi)/2); continue\n        acc_i = correct[mask].mean(); conf_i = confidences[mask].mean(); frac_i = mask.mean()\n        ece += abs(acc_i - conf_i) * frac_i\n        bin_accs.append(acc_i); bin_confs.append(conf_i)\n    import matplotlib.pyplot as plt\n    plt.figure(); plt.plot([0,1],[0,1], linestyle='--')\n    plt.bar(xs, bin_accs, width=1.0/n_bins, alpha=0.6, edgecolor='k')\n    plt.plot(xs, bin_confs, marker='o')\n    plt.xlabel('Confidence'); plt.ylabel('Accuracy')\n    plt.title(f'Reliability Diagram (ECE={ece:.3f})')\n    plt.tight_layout(); plt.show()\n    return float(ece)\n\nece = reliability_diagram_inline(yt, pt, n_bins=15)\nprint('ECE =', ece)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}