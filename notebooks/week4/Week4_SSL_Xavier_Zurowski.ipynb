{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip -q install torch torchvision medmnist scikit-learn matplotlib tqdm\n"
      ],
      "id": "install"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_f4qaP6oURqV"
      },
      "outputs": [],
      "source": [
        "import os, random, json, numpy as np\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms.v2 as vT\n",
        "import torchvision.models as tvm\n",
        "import matplotlib.pyplot as plt\n",
        "import medmnist\n",
        "from medmnist import INFO\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class SSLDataset(Dataset):\n",
        "  def __init__(self, base_dataset, ssl_transform):\n",
        "    self.base = base_dataset\n",
        "    self.transform = ssl_transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.base)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x,_ = self.base[idx]\n",
        "    v1 = self.transform(x)\n",
        "    v2 = self.transform(x)\n",
        "    return v1,v2\n",
        "\n",
        "def get_medmnist_train(key: str, download=True):\n",
        "    info = INFO[key]\n",
        "    DataClass = getattr(medmnist, info['python_class'])\n",
        "    base_transform = vT.Compose([\n",
        "        vT.Resize(224),\n",
        "        vT.ToImage(),\n",
        "        vT.ToDtype(torch.float32, scale=True),\n",
        "        vT.Lambda(lambda x: x.repeat(3,1,1) if x.shape[0] == 1 else x),\n",
        "    ])\n",
        "    return DataClass(split=\"train\", transform=base_transform, download=download)\n",
        "\n",
        "ssl_transform = vT.Compose([\n",
        "    vT.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
        "    vT.RandomHorizontalFlip(p=0.5),\n",
        "    vT.RandomRotation(degrees=10),\n",
        "    vT.GaussianNoise(sigma=0.01),\n",
        "    # vT.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5)),\n",
        "    vT.ColorJitter(brightness=0.05, contrast=0.05),\n",
        "    vT.Normalize(mean=[0.485,0.456,0.406],\n",
        "                 std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "class ResNet18Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        m = tvm.resnet18(weights=tvm.ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.features = nn.Sequential(*list(m.children())[:-1])  # remove classification layer\n",
        "        self.out_dim = 512\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return x.flatten(1)\n",
        "\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, in_dim=512, proj_dim=128):\n",
        "      super().__init__()\n",
        "      self.net = nn.Sequential(\n",
        "          nn.Linear(in_dim, in_dim),\n",
        "          nn.BatchNorm1d(in_dim),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Linear(in_dim, proj_dim),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def nt_xent_loss (z1, z2, tau=0.2):\n",
        "  B = z1.size(0)\n",
        "\n",
        "  z1 = F.normalize(z1, dim=1)\n",
        "  z2 = F.normalize(z2, dim=1)\n",
        "\n",
        "  z = torch.cat([z1,z2], dim=0) #stack matrix rows, (z1 and z2 have shape [B, D], z has shape [2B,D])\n",
        "\n",
        "  sim = z @ z.T/tau #cosine similarity since z1 and z2 are normalized\n",
        "\n",
        "  mask = torch.eye(2*B, device=z.device).bool()\n",
        "  sim = sim.masked_fill(mask, -1e9) #mask diagonal entries that correspond to paired augmentations\n",
        "\n",
        "  labels = (torch.arange(2*B, device=z.device) + B) % (2*B)\n",
        "  return F.cross_entropy(sim, labels)"
      ],
      "id": "_f4qaP6oURqV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jsniv6SURqV"
      },
      "outputs": [],
      "source": [
        "# ---- Config (choose ONE binary dataset) ----\n",
        "set_seed(42)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device:', device)\n",
        "\n",
        "DATASET_KEY = 'breastmnist'  # or 'breastmnist'\n",
        "EPOCHS      = 50\n",
        "BATCH_SIZE  = 128\n",
        "LR          = 1e-3\n",
        "WEIGHT_DECAY= 1e-4\n",
        "TAU = 0.2\n",
        "\n",
        "save_dir = \"results/week4\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "id": "1jsniv6SURqV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eO2EM8DtURqV"
      },
      "outputs": [],
      "source": [
        "base_ds = get_medmnist_train(DATASET_KEY)\n",
        "ssl_ds = SSLDataset(base_ds, ssl_transform)\n",
        "ssl_loader = DataLoader (ssl_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "encoder = ResNet18Encoder().to(device)\n",
        "proj_head = ProjectionHead().to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(encoder.parameters()) + list(proj_head.parameters()),\n",
        "    lr=LR,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        ")\n",
        "\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    encoder.train()\n",
        "    proj_head.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for v1, v2 in ssl_loader:\n",
        "        v1 = v1.to(device)\n",
        "        v2 = v2.to(device)\n",
        "\n",
        "        h1 = encoder(v1)\n",
        "        h2 = encoder(v2)\n",
        "        z1 = F.normalize(proj_head(h1), dim=1)\n",
        "        z2 = F.normalize(proj_head(h2), dim=1)\n",
        "\n",
        "        loss = nt_xent_loss(z1, z2, tau=TAU)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * v1.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(ssl_loader.dataset)\n",
        "    loss_history.append(epoch_loss)\n",
        "    print(f\"[SSL] Epoch {epoch:03d}/{EPOCHS} | loss={epoch_loss:.4f}\")\n",
        "\n",
        "torch.save(encoder.state_dict(), f\"{save_dir}/ssl_encoder.pt\")\n",
        "torch.save(proj_head.state_dict(), f\"{save_dir}/ssl_proj_head.pt\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"NT-Xent loss\")\n",
        "plt.title(\"SSL Loss Curve\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{save_dir}/ssl_loss_curve.png\")\n",
        "plt.close()\n",
        "\n",
        "ssl_config = {\n",
        "    \"method\": \"simclr-lite\",\n",
        "    \"dataset\": DATASET_KEY,\n",
        "    \"backbone\": \"resnet18\",\n",
        "    \"proj_dim\": 128,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"epochs\": EPOCHS,\n",
        "    \"lr\": LR,\n",
        "    \"weight_decay\": WEIGHT_DECAY,\n",
        "    \"augmentations\": \"RandomResizedCrop+Flip+Rot+Jitter, GussianNoise\",\n",
        "    \"tau\": TAU,\n",
        "    \"seed\": 42,\n",
        "}\n",
        "\n",
        "with open(f\"{save_dir}/ssl_config.json\", \"w\") as f:\n",
        "    json.dump(ssl_config, f, indent=4)\n",
        "\n",
        "\n"
      ],
      "id": "eO2EM8DtURqV"
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.half()  # convert all weights to float16\n",
        "torch.save(encoder.state_dict(), f\"{save_dir}/ssl_encoder_fp16.pt\")"
      ],
      "metadata": {
        "id": "JORVp1zCJPyk"
      },
      "id": "JORVp1zCJPyk",
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}